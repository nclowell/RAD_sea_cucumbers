{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering & Plots\n",
    "\n",
    "This notebook is for streamlining the filtering process that occurs after ipyrad. This way, I can rerun the notebook with different filenames instead of do it from scratch each time.\n",
    "\n",
    "\n",
    "### Naming Cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### What are we filtering for today?\n",
    "filter_biall = \"TRUE\" # either TRUE or FALSE\n",
    "filter_MAF = \"TRUE\" # either TRUE or FALSE\n",
    "filter_HWE = \"FALSE\" # either TRUE or FALSE\n",
    "\n",
    "### Other necessary parameters for this notebook\n",
    "assembly_name = \"PC_allR_1M_20K_ref_001_gi001\"\n",
    "popassignpath = \"../../pop_assgn_files/PC_all_pop_assignment_lowRD.txt\"\n",
    "dir_outfiles = \"/mnt/hgfs/E/Ipyrad/PC_allR_1M_20K_ref_001_gi001_outfiles/\"\n",
    "date = \"20190222\"\n",
    "plot_subtitle = \"\" # leave blank if you don't want to add a subtitle\n",
    "alpha = 0.01 # significance level for HWE test\n",
    "pop_thresh = 3 # if a locus is out of HWE in more than this many populations, it will get filtered out\n",
    "f = \"1\" # string of 1 or two for Genepop header format; 1 means loci each on a line, 2 means all in same line with commas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working Cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individuals =270.0\n",
      "Number of individuals WITH FAKE POP = 273.0\n",
      "Number of loci before HWE = 848\n"
     ]
    }
   ],
   "source": [
    "# import all necessary modules\n",
    "import os\n",
    "import subprocess as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "# name all intermediate files\n",
    "ipy_VCF = assembly_name + \".vcf\" # e.g., CG_l1_25_c86_H.vcf\n",
    "filt_VCF_out = assembly_name # e.g., CG_l1_25_c86_H\n",
    "if filter_biall == \"TRUE\": \n",
    "    filt_VCF_out += \"_biall\" # e.g., CG_l1_25_c86_H_biall\n",
    "if filter_MAF == \"TRUE\":\n",
    "    filt_VCF_out += \"_maf\" # e.g., CG_l1_25_c86_H_biall_maf\n",
    "else:\n",
    "    filt_VCF_out += \"_NOmaf\" # e.g., CG_l1_25_c86_H_biall_NOmaf\n",
    "filt_VCF_out_recode = filt_VCF_out + \".recode.vcf\" # e.g.,CG_l1_25_c86_H_biall_maf.recode.vcf\n",
    "one_VCF = filt_VCF_out.split(\".\")[0] + \"_oneSNP.vcf\" # e.g., CG_l1_25_c86_H_biall_maf_oneSNP.vcf\n",
    "one_str_file = one_VCF[:-3] + \"str\" # e.g., CG_l1_25_c86_H_biall_maf_oneSNP.str\n",
    "str_inames_file = one_VCF[:-4] + \"_inames.str\" # e.g., CG_l1_25_c86_H_biall_maf_oneSNP_inames.str\n",
    "str_inames_fpop_file = one_VCF[:-4] + \"_inames_fpop.str\" # e.g., CG_l1_25_c86_H_biall_maf_oneSNP_inames_fpop.str\n",
    "\n",
    "# change wd\n",
    "os.chdir(dir_outfiles)\n",
    "\n",
    "# make directory for new output files, if doesn't already exist\n",
    "if not os.path.exists(\"new_outfiles\"):\n",
    "    os.makedirs(\"new_outfiles\")\n",
    "    \n",
    "# make VCFtools call string\n",
    "vcf_call = \"vcftools --vcf \" + ipy_VCF + \" \"\n",
    "if filter_biall == \"TRUE\":\n",
    "    vcf_call += \"--min-alleles 2 --max-alleles 2 \"\n",
    "if filter_MAF == \"TRUE\":\n",
    "    vcf_call += \"--maf .05 \"\n",
    "vcf_call += \"--out new_outfiles/\" + filt_VCF_out + \" \"\n",
    "vcf_call += \"--recode-INFO-all --recode\"\n",
    "\n",
    "# call VCFtools\n",
    "sp.call([vcf_call],shell=True)\n",
    "\n",
    "# change wd to new outfiles\n",
    "os.chdir(\"new_outfiles\")\n",
    "\n",
    "# make oneSNP call string\n",
    "one_call = \"python ../../oneSNP.py \" + filt_VCF_out_recode + \" \" + one_VCF\n",
    "\n",
    "# call oneSNP script to filter one SNP per RAD tag\n",
    "sp.call([one_call], shell=True)\n",
    "\n",
    "# double-check number of loci in VCF file\n",
    "vcf_file = open(one_VCF,\"r\") \n",
    "vcf_file_lines = vcf_file.readlines()\n",
    "vcf_file.close()\n",
    "        \n",
    "locus_names = {}\n",
    "snp_name_count = 1\n",
    "\n",
    "for line in vcf_file_lines:\n",
    "    if line[0] != \"#\":\n",
    "        linelist = line.strip().split()\n",
    "        locus = linelist[0]\n",
    "        pos = linelist[1]\n",
    "        vcf_locus_name = locus + \"_\" + pos\n",
    "        str_locus_name = \"SNP_\" + str(snp_name_count)\n",
    "        snp_name_count += 1\n",
    "        locus_names[str_locus_name] = vcf_locus_name  \n",
    "        \n",
    "# get sample list and snp name list for rewriting header to structure file       \n",
    "sample_list = []\n",
    "snp_name_list = []\n",
    "rdd = {} \n",
    "\n",
    "for line in vcf_file_lines:\n",
    "    if line[0:1] == \"#C\":\n",
    "        linelist = line.strip().split()\n",
    "        sample_list += linelist[9:]\n",
    "    elif line[0] != \"#\": # ignore header lines\n",
    "        genblocks = line.strip().split()\n",
    "        snp_name = genblocks[0] + \"_\" + genblocks[1] # name format e.g., locus_47_1\n",
    "        snp_name_list.append(snp_name)\n",
    "        for genblock in genblocks[9:]: # start on genotype lines\n",
    "            genblocklist = genblock.split(\":\")\n",
    "            rd = int(genblocklist[1])\n",
    "            if snp_name not in rdd:\n",
    "                rdd[snp_name] = [rd]\n",
    "            elif snp_name in rdd:\n",
    "                rdd[snp_name] += [rd]\n",
    "            else:\n",
    "                print \"something funky going on\"\n",
    "                \n",
    "                \n",
    "# PGD Spider transform VCF to STR\n",
    "\n",
    "# change to PGD Spider directory\n",
    "os.chdir(\"/mnt/hgfs/SHARED_FOLDER/Software/PGDSpider_2.1.1.0\")\n",
    "\n",
    "# make PGD call string\n",
    "PGD_call = \"java -Xmx1024m -Xms512m -jar PGDSpider2-cli.jar \"\n",
    "PGD_call += \"-inputfile \" + dir_outfiles + \"/new_outfiles/\" + one_VCF\n",
    "PGD_call += \" -outputfile \" + dir_outfiles + \"/new_outfiles/\" + one_str_file\n",
    "PGD_call += \" -inputformat VCF -outputformat STRUCTURE \"\n",
    "PGD_call += \"-spid vcf_to_str.spid\"\n",
    "\n",
    "# call PGD to make STR file\n",
    "sp.call([PGD_call], shell = True)\n",
    "\n",
    "# change wd back to new outfiles\n",
    "os.chdir(dir_outfiles + \"/new_outfiles\")\n",
    "\n",
    "# rename structure file header\n",
    "old_str = open(one_str_file, \"r\")\n",
    "old_str_lines = old_str.readlines()\n",
    "old_str.close()\n",
    "\n",
    "new_str_header = \"\\t\\t\" # will need to change this line when I get a hold of better code for one SNP/tag\n",
    "old_str_header_list = old_str_lines[0].strip().split()\n",
    "for snpname in snp_name_list:\n",
    "    new_str_header += snpname + \" \"\n",
    "new_str_header = new_str_header[:-1]\n",
    "new_str = open(str_inames_file, \"w\")\n",
    "new_str.write(new_str_header + \"\\n\")\n",
    "for line in old_str_lines[1:]:\n",
    "    new_str.write(line)\n",
    "new_str.close()\n",
    "\n",
    "# add fake pop for analyzing populations together in hierfstat\n",
    "str_onesnp_file = open(str_inames_file, \"r\")\n",
    "str_onesnp_file_lines = str_onesnp_file.readlines()\n",
    "str_onesnp_file.close()\n",
    "\n",
    "fpop_lines = []\n",
    "\n",
    "for line in str_onesnp_file_lines[-6:]:\n",
    "    linelist = line.strip().split()\n",
    "    newline = \"FALSE\" + linelist[0] + \"\\t\" + \"2\" + \"\\t\"\n",
    "    for genotype in linelist[2:]:\n",
    "        newline += genotype + \" \"\n",
    "    newline = newline[:-1] + \"\\n\"\n",
    "    fpop_lines.append(newline)\n",
    "\n",
    "str_file_fpop =open(str_inames_fpop_file, \"w\")\n",
    "\n",
    "for line in str_onesnp_file_lines:\n",
    "    str_file_fpop.write(line)\n",
    "for line in fpop_lines:\n",
    "    str_file_fpop.write(line)\n",
    "str_file_fpop.close()\n",
    "\n",
    "numloci = len(str_onesnp_file_lines[0].strip().split())\n",
    "numinds = int(float(len(fpop_lines)+len(str_onesnp_file_lines)-1))/float(2)\n",
    "\n",
    "print \"Number of individuals =\" + str(numinds - 3)\n",
    "print \"Number of individuals WITH FAKE POP = \" + str(numinds) \n",
    "print \"Number of loci before HWE = \" + str(numloci)\n",
    "\n",
    "# make R call string\n",
    "string_callR = \"Rscript ../../pop_gen_stats.R \"\n",
    "string_callR += dir_outfiles + \"new_outfiles \"\n",
    "string_callR += str_inames_fpop_file + \" \"\n",
    "string_callR += str(numinds) + \" \" + str(numloci) + \" \" + date\n",
    "\n",
    "# run R script using call string\n",
    "sp.call([string_callR],shell=True)\n",
    "\n",
    "# names of pop gen stats files + name for plot title\n",
    "assembly_name_plots = assembly_name\n",
    "str_filename = str_inames_fpop_file\n",
    "fis_filename = \"Fis_\" + str_inames_fpop_file[:-4] + \"_\" + date + \".txt\"\n",
    "ho_filename = \"Ho_\" + str_inames_fpop_file[:-4] + \"_\" + date + \".txt\"\n",
    "hs_filename = \"Hs_\" + str_inames_fpop_file[:-4] + \"_\" + date + \".txt\"\n",
    "\n",
    "# make read depth plot\n",
    "vcf_file_fplot = open(one_VCF,\"r\") # change!\n",
    "vcf_file_lines = vcf_file_fplot.readlines()\n",
    "vcf_file.close()\n",
    "\n",
    "locus_names = {}\n",
    "snp_name_count = 1\n",
    "\n",
    "for line in vcf_file_lines:\n",
    "    if line[0] != \"#\":\n",
    "        linelist = line.strip().split()\n",
    "        locus = linelist[0]\n",
    "        pos = linelist[1]\n",
    "        vcf_locus_name = locus + \"_\" + pos\n",
    "        str_locus_name = \"SNP_\" + str(snp_name_count)\n",
    "        snp_name_count += 1\n",
    "        locus_names[str_locus_name] = vcf_locus_name  \n",
    "\n",
    "sample_list = []\n",
    "snp_name_list = []\n",
    "rdd = {} \n",
    "\n",
    "for line in vcf_file_lines:\n",
    "    if line[0:1] == \"#C\":\n",
    "        linelist = line.strip().split()\n",
    "        sample_list += linelist[9:]\n",
    "    elif line[0] != \"#\": # ignore header lines\n",
    "        genblocks = line.strip().split()\n",
    "        snp_name = genblocks[0] + \"_\" + genblocks[1] # name formate.g., locus_47_1\n",
    "        snp_name_list.append(snp_name)\n",
    "        for genblock in genblocks[9:]: # start on genotype lines\n",
    "            genblocklist = genblock.split(\":\")\n",
    "            rd = int(genblocklist[1])\n",
    "            if snp_name not in rdd:\n",
    "                rdd[snp_name] = [rd]\n",
    "            elif snp_name in rdd:\n",
    "                rdd[snp_name] += [rd]\n",
    "            else:\n",
    "                print \"something funky going on\"\n",
    "\n",
    "locus_rd_avs = []\n",
    "for snp in snp_name_list:\n",
    "    locus_rd_avs.append(np.mean(rdd[snp]))\n",
    "    \n",
    "plt.hist(locus_rd_avs, bins = np.arange(0,max(locus_rd_avs)+1,4)-2)\n",
    "\n",
    "title = one_VCF\n",
    "if len(plot_subtitle) > 1:\n",
    "    title += \"\\n\" + plot_subtitle\n",
    "plt.title(title)\n",
    "\n",
    "plt.xlabel(\"Read depth\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.savefig('rd_' + filt_VCF_out + '.png')\n",
    "plt.close()\n",
    "\n",
    "# make Fis plot\n",
    "\n",
    "fis_file = open(fis_filename,\"r\")\n",
    "fis_file_lines = fis_file.readlines()\n",
    "fis_file.close()\n",
    "\n",
    "fis_list = []\n",
    "fis_pls_NAs = []\n",
    "\n",
    "for line in fis_file_lines[1:]:\n",
    "    fis = line.strip().split()[1]\n",
    "    fis_pls_NAs.append(fis)\n",
    "    if fis != \"NA\":\n",
    "        fis_list.append(float(fis))\n",
    "    \n",
    "plt.hist(fis_list, bins = np.arange(-1.2,1.2,.05)-.025)\n",
    "\n",
    "title = \"Fis in \" + filt_VCF_out\n",
    "if len(plot_subtitle) > 1:\n",
    "    title += \"\\n\" + plot_subtitle\n",
    "plt.title(title)\n",
    "\n",
    "plt.xlabel(\"Fis\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.savefig(\"Fis_\" + filt_VCF_out + '.png')\n",
    "plt.close()\n",
    "\n",
    "# make Ho plot\n",
    "\n",
    "ho_file = open(ho_filename,\"r\")\n",
    "ho_file_lines = ho_file.readlines()\n",
    "ho_file.close()\n",
    "\n",
    "ho_list = []\n",
    "ho_and_NAs = []\n",
    "\n",
    "for line in ho_file_lines[1:]:\n",
    "    ho = line.strip().split()[1]\n",
    "    ho_and_NAs.append(ho)\n",
    "    if ho != \"NA\":\n",
    "        ho_list.append(float(ho))\n",
    "    \n",
    "plt.hist(ho_list, bins = np.arange(0,1.2,.05)-.025)\n",
    "\n",
    "\n",
    "title = \"Ho in \" + filt_VCF_out\n",
    "if len(plot_subtitle) > 1:\n",
    "    title += \"\\n\" + plot_subtitle\n",
    "plt.title(title)\n",
    "\n",
    "plt.xlabel(\"Ho\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"Ho in \" + filt_VCF_out + '.png')\n",
    "plt.close()\n",
    "\n",
    "# make Hs plot\n",
    "\n",
    "hs_file = open(hs_filename,\"r\")\n",
    "hs_file_lines = hs_file.readlines()\n",
    "hs_file.close()\n",
    "\n",
    "hs_list = []\n",
    "hs_and_NAs = []\n",
    "\n",
    "for line in hs_file_lines[1:]:\n",
    "    hs = line.strip().split()[1]\n",
    "    hs_and_NAs.append(hs)\n",
    "    if hs != \"NA\":\n",
    "        hs_list.append(float(hs))\n",
    "    \n",
    "plt.hist(hs_list, bins = np.arange(0,1.2,.025)-.0125)\n",
    "\n",
    "title = \"Hs in \" + filt_VCF_out\n",
    "if len(plot_subtitle) > 1:\n",
    "    title += \"\\n\" + plot_subtitle\n",
    "plt.title(title)\n",
    "\n",
    "plt.xlabel(\"Hs\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"Hs_\" + filt_VCF_out + '.png')\n",
    "plt.close()\n",
    "\n",
    "# add population IDs to structure file\n",
    "\n",
    "os.chdir(dir_outfiles + \"/new_outfiles\")\n",
    "str_withpops = str_inames_file.split(\".\")[0] + \"_wpops.str\"\n",
    "call_pscript_addpopIDs = \"python ../../add_popIDs_to_str_files.py -i \" + str_inames_file + \" -p \" + popassignpath + \" -o \" + str_withpops\n",
    "sp.call([call_pscript_addpopIDs],shell=True)\n",
    "\n",
    "if filter_HWE == \"TRUE\":\n",
    "    # PGD Spider transform STR to Genepop\n",
    "\n",
    "    # change to PGD Spider directory\n",
    "    os.chdir(\"/mnt/hgfs/SHARED_FOLDER/Software/PGDSpider_2.1.1.0\")\n",
    "\n",
    "    # make PGD call string\n",
    "    PGD_call2 = \"java -Xmx1024m -Xms512m -jar PGDSpider2-cli.jar \"\n",
    "    PGD_call2 += \"-inputfile \" + dir_outfiles + \"new_outfiles/\" + str_withpops\n",
    "    PGD_call2 += \" -outputfile \" + dir_outfiles + \"new_outfiles/\" + str_withpops.split(\".\")[0] + \".txt\"\n",
    "    PGD_call2 += \" -inputformat STRUCTURE -outputformat GENEPOP \"\n",
    "    PGD_call2 += \"-spid str_to_GP.spid\"\n",
    "\n",
    "    # call PGD to make Genepop file\n",
    "    sp.call([PGD_call2], shell = True)\n",
    "\n",
    "    # change wd back to new outfiles\n",
    "    os.chdir(dir_outfiles + \"/new_outfiles\")\n",
    "\n",
    "    # Run HWE exact test from genepop package in R\n",
    "\n",
    "    # make R call string for running HWE test in R, package genepop\n",
    "    string_callR2 = \"Rscript ../../HWE_inR_forpipeline.R \"\n",
    "    string_callR2 += dir_outfiles + \"new_outfiles \"\n",
    "    string_callR2 += str_withpops.split(\".\")[0] + \".txt\" + \" \"\n",
    "    string_callR2 += date\n",
    "\n",
    "    # run R script using call string\n",
    "    sp.call([string_callR2],shell=True)\n",
    "\n",
    "    # Make output file with loci that pass HWE test, with specified alpha & population number threshold\n",
    "\n",
    "    # read in file and select middle chunk, with data on Results by Locus, and make list of lines\n",
    "    HWE_P_file = str_withpops.split(\".\")[0] + \"_HWE_pfile.txt\"\n",
    "    infile = open(HWE_P_file,\"r\")\n",
    "    infile_text = infile.read() \n",
    "    infile_text_noheader = infile_text.split(\"Results by\")[1]\n",
    "    lines = infile_text_noheader.split(\"\\n\")\n",
    "\n",
    "    pval_dict = {} # make a dictionary to store P values from Results by Locus section\n",
    "    popnames = [] # make list for population names, as named in Genepop (an individual from the pop)\n",
    "    header_count = 2 # a counter to help the script iterate over locus blocks in the output file\n",
    "    last_locus = \"\" # initiate an object outside of loop to help script iterate over locus blocks in the output file\n",
    "    ordered_loci = []\n",
    "    # iterate through lines and feed dictionary, with key locus and value a list of Pvalues for each population\n",
    "    for line in lines:\n",
    "        if line.startswith(\"Locus \") and header_count == 2:\n",
    "            header_count = 0\n",
    "            linelist = line.strip().split()\n",
    "            locus_name = linelist[1].replace('\"','')\n",
    "            last_locus = locus_name\n",
    "            pval_dict[locus_name] = []\n",
    "            ordered_loci.append(locus_name)\n",
    "        elif header_count == 2 and len(line.strip().split()) > 1 and line.startswith(\"All\") == False and line.startswith(\" \") == False:\n",
    "            linelist = line.strip().split()\n",
    "            popname = linelist[0]\n",
    "            if popname not in popnames:\n",
    "                popnames.append(popname)\n",
    "            if linelist[1] == \"-\":\n",
    "                pval_dict[locus_name].append(\"NA\")\n",
    "            else:\n",
    "                pval_dict[locus_name].append(float(linelist[1]))\n",
    "        elif line.startswith(\"-\"):\n",
    "            header_count += 1\n",
    "    infile.close()\n",
    "\n",
    "    # store names of loci that pass and fail HWE test according to assigned alpha and population number threshold\n",
    "    loci_keep_names = []\n",
    "    loci_lost_names = []\n",
    "\n",
    "    for locus in pval_dict.keys():\n",
    "        sig_count = 0\n",
    "        output_list = pval_dict[locus]\n",
    "        for value in output_list:\n",
    "            if value != \"NA\":\n",
    "                if value < alpha:\n",
    "                    sig_count += 1\n",
    "        if sig_count > pop_thresh:\n",
    "            loci_lost_names.append(locus)\n",
    "        else:\n",
    "            loci_keep_names.append(locus)\n",
    "\n",
    "    loci_kept = len(loci_keep_names)\n",
    "    loci_lost = len(loci_lost_names)\n",
    "    perc_lost = float(len(loci_lost_names))/float(len(loci_keep_names)+ len(loci_lost_names))\n",
    "\n",
    "    print \"Number of loci after HWE = \" + str(loci_kept)\n",
    "\n",
    "    # name output file of loci kept and lost after HWE filtering\n",
    "    post_HWE_kept_loci = str_withpops.split(\".\")[0] + \"_HWEkeptloci.txt\"\n",
    "    post_HWE_lost_loci = str_withpops.split(\".\")[0] + \"_HWElostloci.txt\"\n",
    "\n",
    "    # write output files\n",
    "\n",
    "    out_kept = open(post_HWE_kept_loci,\"w\")\n",
    "    for locus_name in loci_keep_names:\n",
    "        out_kept.write(locus_name + \"\\n\")\n",
    "    out_kept.close()\n",
    "\n",
    "    out_lost = open(post_HWE_lost_loci,\"w\")\n",
    "    for locus_name in loci_lost_names:\n",
    "        out_lost.write(locus_name + \"\\n\")\n",
    "    out_lost.close()\n",
    "\n",
    "    # filter out loci that weren't in HWE using script\n",
    "\n",
    "    # make call string for running python script that subsets HWE with list of loci to keep\n",
    "    subset_GP_call = \"python ../../subset_GP_forloci.py -i \"\n",
    "    subset_GP_call += str_withpops.split(\".\")[0] + \".txt -l \"\n",
    "    subset_GP_call += str_withpops.split(\".\")[0] + \"_HWEkeptloci.txt -o \"\n",
    "    subset_GP_call += str_withpops.split(\".\")[0] + \"_fHWE.gen -f \" + f \n",
    "\n",
    "    # run python script using call string\n",
    "    sp.call([subset_GP_call],shell=True)\n",
    "\n",
    "    # make simple DAPC plot using R script\n",
    "\n",
    "    # make call string for running dapc R script\n",
    "    DAPC_call = \"Rscript ../../DAPC_forpipeline.R \"\n",
    "    DAPC_call += dir_outfiles + \"new_outfiles \"\n",
    "    DAPC_call += str_withpops.split(\".\")[0] + \"_fHWE.gen \"\n",
    "    DAPC_call += date + \" \"\n",
    "    DAPC_call += str(numinds - 3) + \" \" + str(len(popnames)) \n",
    "\n",
    "    # run DAPC R script using call string\n",
    "    sp.call([DAPC_call],shell=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For checking file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipy_VCF:   CG_allR_1M_002.vcf\n",
      "filt_VCF_out:   CG_allR_1M_002_biall_maf\n",
      "filt_VCF_out_recode:   CG_allR_1M_002_biall_maf.recode.vcf\n",
      "one_VCF:   CG_allR_1M_002_biall_maf_oneSNP.vcf\n",
      "one_str_file:   CG_allR_1M_002_biall_maf_oneSNP.str\n",
      "str_inames_file:   CG_allR_1M_002_biall_maf_oneSNP_inames.str\n",
      "str_inames_fpop_file:   CG_allR_1M_002_biall_maf_oneSNP_inames_fpop.str\n"
     ]
    }
   ],
   "source": [
    "print \"ipy_VCF:   \" + ipy_VCF\n",
    "print \"filt_VCF_out:   \" + filt_VCF_out\n",
    "print \"filt_VCF_out_recode:   \" + filt_VCF_out_recode\n",
    "print \"one_VCF:   \" + one_VCF\n",
    "print \"one_str_file:   \" + one_str_file\n",
    "print \"str_inames_file:   \" + str_inames_file\n",
    "print \"str_inames_fpop_file:   \" + str_inames_fpop_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
